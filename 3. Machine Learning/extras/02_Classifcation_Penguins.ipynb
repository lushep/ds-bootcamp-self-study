{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=../images/gdd-logo.png width=300px align=right>\n",
    "\n",
    "# Classification\n",
    "\n",
    "In this notebook, we shall classify penguins species based on bodily measurements using the Scikit-Learn API. \n",
    "\n",
    "We shall first introduce the dataset and the Scikit-Learn library. Afterwards we will cover the following aspects:\n",
    "\n",
    "- [Loading in the data](#loading-in-the-data)    \n",
    "    - [<mark>Exploring the dataset</mark>](#exploring-the-dataset) \n",
    "    - [Visualising the dataset](#visualising-the-dataset)  \n",
    "- [Preparing the data for sklearn](#preparing)\n",
    "    - [Splitting the dataset](#train-test-split)\n",
    "- [Model creation & evaluation](#model)\n",
    "    - [Training and evaluating a Scikit-Learn model](#steps)\n",
    "    - [Alternative metrics](#metrics)\n",
    "    - [Prediction and Inference](#inference)\n",
    "    - [Visualising the model](#vis)\n",
    "    - [<mark>Choosing a different model</mark>](#choosing-models)  \n",
    "\n",
    "![](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "The data was collected and made available by Dr. Kristen Gorman and the Palmer Station, Antartica LTER. Their goal was to provide a great dataset for data exploration, visualisation and - in this case - a demonstration of the Scikit-Learn API. \n",
    "\n",
    "The data set contains measurements for different species of penguins living at the Palmer station:\n",
    "\n",
    "|Field|Description|\n",
    "|:---|:---|\n",
    "|species|The species of the penguin: Adelie, Chinstrap or Gentoo|\n",
    "|island|The island on which the penguin was spotted|\n",
    "|bill_length_mm|The length of the penguin's bill in mm|\n",
    "|bill_depth_mm|The depth of the penguin's bill in mm|\n",
    "|flipper_length_mm|The length of the penguin's flipper in mm|\n",
    "|body_mass_g|The weight of the penguin in grams|\n",
    "|sex|The gender of the penguin - Female or Male|\n",
    "\n",
    "<img src=\"../images/02_Classification_Penguins/culmen_depth.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "Scikit-Learn is *the* library for machine learning in Python. You could consider it the swiss army knife of machine learning. A wide variety of machine learning models are implemented by the community and core developers, with a consistent API. Once you master this API, it's easy to apply a wide variety of machine learning algorithms, and you have a handy tool to help you out with preprocessing, model evaluation and model selection. \n",
    "\n",
    "#### Why Scikit-Learn?\n",
    "- Many available machine learning models\n",
    "- Models are implemented by an expert team and checked by a large community\n",
    "- Covers most machine-learning tasks\n",
    "- Commitment to documentation, consistency and usability\n",
    "- Designed to work with other key Python libraries (NumPy, Pandas etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'loading-in-the-data'></a>\n",
    "## 1. Loading in the data\n",
    "\n",
    "There are many places your data can originate from. Maybe you want to load it from a Excel file you have stored locally on your system, maybe you have a .csv file stored online somewhere. Scikit-learn comes with various standard datasets that can be used for practice, that can be loaded if you have Scikit-Learn installed on your system. \n",
    "\n",
    "Our dataset will be loaded in as a Pandas dataframe and can be used as such. Pandas is a powerful library for data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv('../data/penguins.csv')\n",
    "penguins.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'exploring-the-dataset'></a>\n",
    "## <mark> Exercise: Exploring the dataset </mark>\n",
    "\n",
    "Below are some typical things you may want to check as part of your initial investigation of the dataset.\n",
    "\n",
    "1. How many rows and columns are present in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which data types are used by each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How many species are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How many penguins are there for each species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'visualising-the-dataset'></a>\n",
    "## Visualising the dataset \n",
    "\n",
    "To understand the dataset better it can be useful to create some visualisations.\n",
    "\n",
    "Below is a  histogram of the penguin's flipper lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=penguins, x='flipper_length_mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use visualisations to examine how different the data is for the different species.\n",
    "\n",
    "For example, here is a histogram of flipper lengths *for the different species*. Would you be able to separate the species based on this measurement alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=penguins, x='flipper_length_mm', hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the relationship between two variables.\n",
    "\n",
    "Below is a scatter plot of flipper length vs. body mass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be easier to distinguish different species when we look at more than one variable.\n",
    "\n",
    "Here is a a scatter plot of flipper length vs. body mass *for the different species*. Would you be able to separate the species based on the relationship between these measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=penguins, x='flipper_length_mm', y='body_mass_g', hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn also allows us to see this information for each numeric feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=penguins, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'preparing'></a>\n",
    "## 2. Preparing the data for Scikit-Learn\n",
    "\n",
    "The first thing we might notice here is that there are some data point entries that have no value - the value simply says `NaN`. This means this information is missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    penguins\n",
    "    .loc[penguins.isnull().any(axis=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, that also means the information cannot be used as is to create a machine learning model with Scikit-Learn. We must find a way to deal with the missing values. \n",
    "\n",
    "There are multiple strategies for dealing with missing data. For example, you could replace a missing values with the mean of the column. E.g. if for a particular penguin the value for body mass is missing, you could replace the NaN with the mean recorded body mass of all penguins. \n",
    "\n",
    "Scikit-Learn even provides us with a great interface to apply such transformations. For the moment, however, we simply choose to discard all the incomplete data points with pandas `.dropna()` functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_cleaned = penguins.dropna()\n",
    "penguins_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second of all, we notice that we have more information than the penguin measurements _bill length, bill depth, flipper length_ and _body mass_.\n",
    "\n",
    "Although we could incorporate this extra information (sex of the penguin and the island where the penguin was spotted), this requires some extra preprocessing outside of the scope of this notebook. We choose to focus on our four discussed features first.\n",
    "\n",
    "We then use our knowledge of Pandas to create our feature matrix $X$ and target vector $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "X = penguins_cleaned.loc[:, feature_columns]\n",
    "y = penguins_cleaned.loc[:, 'species']\n",
    "\n",
    "print(f'The shape of feature matrix X is: {X.shape}')\n",
    "print(f'The shape of target vector y is: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix columns are also known as the predictive variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target vector is also known as the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature matrix $X$ consists of $n$ samples with $m$ features - in this case $n=333$ and $m=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the feature matrix $X$ corresponds to a value in the target vector $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will then attempt to learn a relationship that can map a row in $X$ to the corresponding value in $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'train-test-split'></a>\n",
    "### Splitting the dataset\n",
    "An important goal of machine learning is to create a model that does not only do well on the data that it has already seen, but will also perform well under new circumstances on data that it has not seen before. We call this _generalization_. \n",
    "\n",
    "Imagine this: Penguin A is a gentoo (bill length of 33, bill depth of of 16, flipper length of 180 and body mass of 3500 grams). \n",
    "\n",
    "<img src=\"../images/02_Classification_Penguins/gentoo.jpg\" width=\"300\">\n",
    "\n",
    "Penguin A was presented during the training of our model; that means, penguin A was one of the examples that the algorithm used to create an understanding of what a gentoo looks like and how you can distinguish it from a chinstrap or adÃ©lie. \n",
    "\n",
    "If we want to know how well our model does, asking the model to classify our penguin A does not give us a lot of information. \n",
    "\n",
    "Even if the model is correct, do we know whether it has really truly learned the relationship between the features and the targets (ie. flipper length of >X is always species Y), or has it simply memorized the original data and does it recognise penguin A from the training phase? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why we want to separate our dataset into two parts:\n",
    "* The _training_ set: this is the data (features and targets) that will guide the learning process. \n",
    "* The _test_ set: this is the data (features and targets) that we will use to _evaluate_ how well our model has learned. \n",
    "\n",
    "<img src=\"../images/02_Classification_Penguins/train-test.png\" width=\"600\">\n",
    "\n",
    "Scikit-Learn's `train_test_split` function allows us to split the data in a train- and test set. By default, the test set size is set to 25% and the data is shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "print(f'The size of our feature matrix for the train set is: {X_train.shape}')\n",
    "print(f'The size of our target vector for the train set is: {y_train.shape}')\n",
    "\n",
    "print(f'\\nThe size of our feature matrix for the test set is: {X_test.shape}')\n",
    "print(f'The size of our target vector for the test set is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our data is in fact shuffled: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'model'></a>\n",
    "## 3. Model creation and evaluation\n",
    "\n",
    "Now we're ready to create our machine learning model! \n",
    "\n",
    "Scikit-Learn has a rich collection of algorithms readily available. Depending on the case you are working on, Scikit-Learn most likely has a model that will suit your purposes. \n",
    "\n",
    "<a id = 'steps'></a>\n",
    "## Training a Scikit-Learn model\n",
    "\n",
    "Below are the steps for training a model using the Scikit-Learn API \n",
    "1. Choosing a model class and importing that model.\n",
    "2. Choosing the model hyperparameters by instantiating this class with desired values.\n",
    "3. Training the model to the preprocessed train data by calling the `fit()` method of the model instance.\n",
    "4. Evaluating model's performance using available metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: import the chosen algorithm \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/02_Classification_Penguins/tree.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: instantiate the model with the chosen hyperparameters\n",
    "model = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: train the model with the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now trained a model that can be used to make predictions on new data. Remember our test set? That's new, unseen data to the model that we can now create predictions on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare these predictions against our original data to see how well our model does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we don't have to do that comparison ourselves. Scikit-Learn has made many implementations of possible metrics readily available, such as accuracy. \n",
    "\n",
    "$\\text{accuracy} = \\frac{correct}{total}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good! \n",
    "\n",
    "Alternatively you can use the `.score()` method. On a Decision Tree this will return the accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'metrics'></a>\n",
    "## Alternative metrics\n",
    "\n",
    "But accuracy is not the only metric you could be interested in. Alternatives are, for example, _precision_ and _recall_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- * _Precision_ is the proportion of positive identifications that was actually correct. \n",
    "* _Recall_ is the proportion of actual positives that was identified correctly.\n",
    "* _F1 score_ is a function of precision and recall, that you use when you seek a balance between precision and recall.  -->\n",
    "\n",
    "#### Precision & Recall\n",
    "\n",
    "Predictions about a class fall into four categories:\n",
    "* True Positive: Correctly predict item is that class\n",
    "* True Negative: Correctly predict item is NOT that class\n",
    "* False Positive: Incorrectly predict item is that class\n",
    "* False Negative: Incorrectly predict item is NOT that class\n",
    "\n",
    "\n",
    "<img src=\"../images/02_Classification_Penguins/TPFN.png\" width=\"350\">\n",
    "\n",
    "In a classification task, the **precision** for a class is the number of true positives (i.e. the number of items correctly labelled as belonging to the positive class) divided by the total number of elements labelled as belonging to the positive class (i.e. the sum of true positives and false positives, which are items incorrectly labelled as belonging to the class).\n",
    "\n",
    "<img src=\"../images/02_Classification_Penguins/precision.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** in this context is defined as the number of true positives divided by the total number of elements that actually belong to the positive class (i.e. the sum of true positives and false negatives, which are items which were not labelled as belonging to the positive class but should have been)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/02_Classification_Penguins/recall.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences between these metrics can be explained with this example:\n",
    "Let's say you create a model that should classify email messages as spam or not spam. _Precision_ measures the percentage of emails flagged as spam that were correctly classified, while _recall_ measures the percentage of actual spam emails that were correctly classified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, precision is more important. For YouTube's recommendation system for example: you won't be able to show _ALL_ relevant videos, but it is important that the ones you do show _are_ relevant. \n",
    "\n",
    "However, in medical context, _recall_ is often more important. After all, if we mistakingly tell a person with cancer that they're healthy, that can have more severe consequences than the other way around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adelie precision comparison\n",
    "(\n",
    "    pd.DataFrame({'y_pred': y_pred, 'y_test': np.array(y_test)})\n",
    "    .loc[lambda df: df['y_pred']=='Adelie']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adelie recall comparison\n",
    "(\n",
    "    pd.DataFrame({'y_test': np.array(y_test), 'y_pred': y_pred})\n",
    "    .loc[lambda df: df['y_test']=='Adelie']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of classes is not too large, we can also produce a confusion matrix to interpret how good the predicitions were.\n",
    "\n",
    "The raw **confusion matrix** can be quickly acquired as shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=y.unique(), index=y.unique())\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.heatmap(confusion_df, annot=True)\n",
    "cm.set(xlabel='predicted label', ylabel='true label', title='Confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `sklearn` the classification report can give us a breakdown of the precision and recall for each species of penguin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 score** is a combination of both precision and recall:\n",
    "\n",
    "${\\displaystyle F_{1}={\\frac {2}{\\mathrm {recall} ^{-1}+\\mathrm {precision} ^{-1}}}=2\\cdot {\\frac {\\mathrm {precision} \\cdot \\mathrm {recall} }{\\mathrm {precision} +\\mathrm {recall} }}={\\frac {\\mathrm {tp} }{\\mathrm {tp} +{\\frac {1}{2}}(\\mathrm {fp} +\\mathrm {fn} )}}}$\n",
    "\n",
    "Precision, recall and F1 are also all available with Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inference'></a>\n",
    "## Prediction and Inference\n",
    "\n",
    "Sometimes our goal may be inference, rather than prediction.\n",
    "\n",
    "**Prediction**: Generalizing the relationship to future observations that the model has not yet seen.\n",
    "\n",
    "**Inference**: Finding which predictors are more associated with the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_df = pd.DataFrame(columns  = X.columns, data = [model.feature_importances_])\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'vis'></a>\n",
    "## Model Visualisation\n",
    "\n",
    "One of the advantages of decision trees over some of the other available models, is that decision trees are relatively easy to interpret. By visualising the tree-like structure of the decision tree, we can understand why the model classifies samples the way it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "\n",
    "plot_tree(model, \n",
    "          ax=ax, \n",
    "          feature_names = feature_columns, \n",
    "          class_names = y.unique());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'choosing-models'></a>\n",
    "## <mark>Choosing a different model </mark>\n",
    "\n",
    "What happens when we're interested in a model other than a decision tree? \n",
    "\n",
    "That's actually really easy. You simply replace the chosen model with another and the rest of the pipeline can stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Uncomment the model that you want to try\n",
    "model = DecisionTreeClassifier()\n",
    "# model = RandomForestClassifier()\n",
    "# model = KNeighborsClassifier()\n",
    "# model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Model accuracy: {model.score(X_test, y_test)}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Scikit-Learn is an excellent, resourceful tool for machine learning in Python. We've seen how we can split a dataset with `train_test_split` into a train and test set, create and train a model, use the trained model to create predictions, and how to use the tools from `sklearn.metrics` to evaluate how good the model is. \n",
    "![](../images/02_Classification_Penguins/palmer-penguins.png) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
