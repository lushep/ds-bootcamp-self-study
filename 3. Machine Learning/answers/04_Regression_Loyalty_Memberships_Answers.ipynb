{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/gdd-logo.png' align=right width=300px>\n",
    "\n",
    "# Sklearn for Linear Regression\n",
    "\n",
    "In this notebook you will use Scikit-Learn to perform Linear Regression on an E-commerce Customer Dataset.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal is to predict the ‘Yearly Amount Spent’ by a customer on an E-commerce platform, so that this information can be used to give the particular customer personalized offers or Loyalty membership etc.\n",
    "\n",
    "The notebook will help you with the initial data exploration, but you will perform the actual modelling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data\n",
    "\n",
    "This is the dataset we will be performing linear regression on.\n",
    "\n",
    "We will try to predict‘Yearly Amount Spent’, so this will be our target vector *or* dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customers = (\n",
    "    pd.read_csv('../data/Ecomm-Customers.csv')\n",
    "    .rename(str.lower, axis='columns')\n",
    ")\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Exercise: Perform some preliminary analysis on the dataset.</mark>\n",
    "\n",
    "* How many customers are in this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['email'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What datatypes does the dataset contain? Are there any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many predictive features are there? Will all the features be informative for the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['avatar'].nunique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Key features:\n",
    "- avg. session length\t\n",
    "- time on app\t\n",
    "- time on website\t\n",
    "- length of membership\n",
    "\n",
    "Notes about the other features:\n",
    "- Email is unique for everyone so not going to be predictive. \n",
    "- We could maybe extract some information from address (country, area etc) to get some more predictive features but for now let's not focus on that.\n",
    "- Avatar could be predictive but there are so many different unique values we'd need to explore more and find a way to group them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many different values are there in the 'Yearly Amount Spent' column? Write a sentence to argue why this is a regression task, rather than classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['yearly amount spent'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['yearly amount spent'].min()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a regression problem due to the amount of unique target values & the fact that they are continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "*Correlation - a statistic that measures the degree to which two variables move in relation to each other.*\n",
    "\n",
    "We will try to learn a model that predicts the yearly amount spent by a customer. However, what if we are able to predict that already from one variable alone? Or what if some variables are not relevant for predicting the yearly amount spent? \n",
    "\n",
    "Let's investigate whether any of the other variables correlate with the yearly amount spent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual inspection\n",
    "\n",
    "Using pairplot we can visualise the relationship between the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feom the plots, ‘Length of Membership’ and ‘Time in App’ appear to be the varibles that have the most correlation with the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix\n",
    "\n",
    "We can also compute the actual pairwise correlation of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap\n",
    "\n",
    "This correlation matrix can be visualised with a heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sns.heatmap(customers.corr(), linewidth=0.5, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with the aforementioned variables, we can see that Avg. Session Length may also be informative for predicting the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>Exercise: Build a Linear Regression Model </mark>\n",
    "\n",
    "### <mark>1. Create Predictor variables 'X' and Target Variable 'y'</mark>\n",
    "\n",
    "For the time being, let’s form our feature matrix using the variables that appear to have a high degree of correlation with the dependent variable.\n",
    "\n",
    "Create the X and y variables. X should have the variables: `Time on App` and `Length of Membership`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['time on app', 'length of membership']\n",
    "X = customers.loc[:, feature_columns]\n",
    "y = customers.loc[:, 'yearly amount spent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>2. Split the data into a training set and a testing set.</mark>\n",
    "\n",
    "We will train our model on the training set and then use the test set to evaluate the model.\n",
    "\n",
    "Reserve 30% of the data for testing and a random seed of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100, test_size=0.3)\n",
    "print(f'X_train shape: {X_train.shape}', \n",
    "      f'X_test shape: {X_test.shape}', \n",
    "      f'y_train shape: {y_train.shape}', \n",
    "      f'X_test shape: {y_test.shape}',\n",
    "     sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> 3. Import the model</mark>\n",
    "\n",
    "Look up how to import a simple [linear regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "Import the model and then instantiate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>4. Train the model</mark>\n",
    "\n",
    "Fit the model to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Intercept and Coefficients\n",
    "\n",
    "## 4. Investigate the model's intercept and coefficients.\n",
    "\n",
    "What are they?\n",
    "\n",
    "```python\n",
    "# Print the intercept\n",
    "print(\"Intercept\", model.intercept_)\n",
    "\n",
    "# Print the coefficients\n",
    "coeff_df = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "print(coeff_df)\n",
    "```\n",
    "\n",
    "*TAKE CARE: Make sure you replace `model` if you have instantiated your model with a different name!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the intercept\n",
    "print(\"Intercept\", model.intercept_)\n",
    "\n",
    "# Print the coefficients\n",
    "coeff_df = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "print(coeff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the model\n",
    "\n",
    "a) What does the intercept represent in this context?\n",
    "\n",
    "b) What do the coefficients represent?\n",
    "\n",
    "c) Are the coefficients comparable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***yearly amount spent = 36.7 * Time on App + 64.8 * Length of Membership - 177.6***\n",
    "\n",
    "Coefficients are not comparable as the `time on app` is MUCH smaller than `length of membership`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Predictions\n",
    "\n",
    "Use your model to make prediction on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([y_test[:10], y_pred[:10]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating Predictions\n",
    "\n",
    "We want to evaluate whether we have made good predictions or not.\n",
    "\n",
    "a) Why would accuracy not be a good metric here?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because with accuracy we are seeing how many targets we managed to get EXACTLY right. We are rarely going to ever be precise with a continuous target, but that doesn't mean we're not really close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual inspection\n",
    "\n",
    "b) **Make a scatter plot** that plots the test set against your predictions.\n",
    "\n",
    "```python\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Test\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "```\n",
    "\n",
    "c) If you're linear regression was really accurate what would you expect to see?\n",
    "How does yours compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Test\")\n",
    "plt.ylabel(\"Predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics\n",
    "\n",
    "Rather than trying to interpret our graph, we can also calculate some metrics.\n",
    "\n",
    "For example, we could calculate the average error of our regression (e.g. how wrong we were on average). The model that gives you the smallest average error would be the best.\n",
    "\n",
    "#### **Coefficient of Determination**, denoted $R^2$ \n",
    "We can use `.score()` method here that, when you apply this method to a Linear Regression model, returns $R^2$.\n",
    "\n",
    "Find the coefficient of determination of your model using the following:\n",
    "\n",
    "```python\n",
    "model.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Coefficient of Determination**, or $R^2$ score, is a **goodness-of-fit** measurement for regression models. \n",
    "\n",
    "It is a measure of the percentage of variance in the target, which the features explain collectively. \n",
    "\n",
    "Accordingly, the $R^2$ score indicates the strength of the relationship between your model and the target on a scale between **0 – 100%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as $R^2$, it is common to report one of the following: \n",
    "\n",
    "- **Mean Absolute Error (MAE)**\n",
    "    -  MAE is the sum of absolute differences between our target and predicted variables. So it measures the average magnitude of errors in a set of predictions, without considering their directions.\n",
    "- **Mean Squared Error (MSE)**\n",
    "    - The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them. The squaring is necessary to remove any negative signs.\n",
    "- **Root Mean Squared Error (RMSE)**\n",
    "    - The RMSE is the square root of the variance of the residuals. It indicates the absolute fit of the model to the data–how close the observed data points are to the model's predicted values. \n",
    "\n",
    "d) Why would it not be ok to just calculate Mean Error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> There are three metrics which are generally used for evaluation of Regression problems (like Linear Regression, Decision Tree Regression, Random Forest Regression etc.):\n",
    "\n",
    "- ***Mean Absolute Error (MAE):*** This measures the absolute average distance between the real data and the predicted data, but it fails to punish large errors in prediction.\n",
    "- ***Mean Square Error (MSE):*** This measures the squared average distance between the real data and the predicted data. Here, larger errors are well noted (better than MAE). But the disadvantage is that it also squares up the units of data as well. So, evaluation with different units is not at all justified.\n",
    "- ***Root Mean Squared Error (RMSE):*** This is actually the square root of MSE. Also, this metrics solves the problem of squaring the units.\n",
    "\n",
    "Hence, all the metrics above measures the average model prediction error ranging between 0 to infinity with negatively oriented scores which means lower the evaluation value better is your model.\n",
    "Choosing better metrics of evaluation is totally dependent to the scenario of your model and data. In short, MSE evaluates with squared units. And mathematically, taking up absolute value for evaluation is quite undesirable, making RMSE a distinct advantageous over other two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import metrics from sklearn and then calulate the following:\n",
    "\n",
    "e) Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE)\n",
    "\n",
    "You can find these in sklearn.metrics: \n",
    "- mean_absolute_error\n",
    "- mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) What is the difference between the metrics, what will MSE/RMSE be more sensitive to than MAE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MSE/RMSE will be more sensitive to outliers in the data as larger diversions from the linear relationship will be pulled out more clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Overfitting\n",
    "\n",
    "By evaluating predictions on the data we trained on we can check for overfitting/underfitting.\n",
    "\n",
    "a) Make predictions on the train set and compute the same metrics as before (MAE, MSE & RMSE).\n",
    "\n",
    "b) What would you expect to see if we were overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_train, train_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_train, train_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> Exercise: Incorporating more features </mark>\n",
    "\n",
    "Remember we had left out a variable which had lesser degree of positive correlation? Add that variable (Avg. Session Length) and see if it improves the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['time on app', 'length of membership', 'avg. session length']\n",
    "X = customers[feature_columns]\n",
    "y = customers.loc[:, 'yearly amount spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100, train_size=0.3)\n",
    "print(f'X_train shape: {X_train.shape}', \n",
    "      f'X_test shape: {X_test.shape}', \n",
    "      f'y_train shape: {y_train.shape}', \n",
    "      f'X_test shape: {y_test.shape}',\n",
    "     sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare performance using the same metrics as before (MAE, MSE & RMSE) when this extra information is included in the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TEST DATA:')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN DATA:')\n",
    "print('MAE:', metrics.mean_absolute_error(y_train, train_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_train, train_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We've now seen regression models and seen how the steps for building a regression model follow that of what we saw in the classification examples. We also saw the need for different metrics."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
